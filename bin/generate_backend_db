#!/usr/bin/env python3

###############################################################################
#
#    Copyright (C) 2021 Ben Woodcroft
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
###############################################################################

__author__ = "Ben Woodcroft"
__copyright__ = "Copyright 2020"
__credits__ = ["Ben Woodcroft"]
__license__ = "GPL3"
__maintainer__ = "Ben Woodcroft"
__email__ = "benjwoodcroft near gmail.com"
__status__ = "Development"

import argparse
import logging
import sys
import os
import shutil
import csv
import subprocess
import tempfile

import extern

sys.path = [os.path.join(os.path.dirname(os.path.realpath(__file__)),'..')] + sys.path

if __name__ == '__main__':
    parent_parser = argparse.ArgumentParser(add_help=False)
    parent_parser.add_argument('--debug', help='output debug information', action="store_true")
    #parent_parser.add_argument('--version', help='output version information and quit',  action='version', version=repeatm.__version__)
    parent_parser.add_argument('--quiet', help='only output errors', action="store_true")

    parent_parser.add_argument('--singlem-db', help='sqlite file from a singlem db', required=True)
    parent_parser.add_argument('--condensed-otu-table', help='condensed OTU table input', required=True)
    parent_parser.add_argument('-o', help='sqlite3 file to generate', required=True)

    args = parent_parser.parse_args()

    # Setup logging
    if args.debug:
        loglevel = logging.DEBUG
    elif args.quiet:
        loglevel = logging.ERROR
    else:
        loglevel = logging.INFO
    logging.basicConfig(level=loglevel, format='%(asctime)s %(levelname)s: %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')

    # Copy file over
    logging.info("Copying SQLite file")
    sqlite_db_path = args.o
    shutil.copy(args.singlem_db, sqlite_db_path)

    # Add new condensed OTU table table
    logging.info("Loading condensed data")
    extern.run('sqlite3 {}'.format(sqlite_db_path), stdin= \
        "CREATE TABLE taxonomies (id INTEGER PRIMARY KEY, taxonomy_level TEXT, parent_id INTEGER, name TEXT); \n"
        "CREATE TABLE condensed_profiles (id INTEGER PRIMARY KEY,"
        " sample_name text, coverage float, taxonomy_id INTEGER);\n")
    
    taxonomy_name_to_id = {}
    next_taxonomy_id = 0

    count = 0
    with open(args.condensed_otu_table, 'r') as csvfile_in:
        reader = csv.reader(csvfile_in, delimiter="\t")

        with tempfile.NamedTemporaryFile() as taxonomy_input_tf:
            # Couldn't get this to work with named pipes, guess it must be possible somehow.
            with tempfile.NamedTemporaryFile() as tf:
                first = True
                for row in reader:
                    if first:
                        first = False
                        continue

                    # Get the taxonomy id, creating a new entry if necessary
                    taxonomies = row[2]
                    taxons_split = taxonomies.split('; ')
                    species_aware_taxonomy = None
                    for (i, taxonomies_split) in enumerate(taxons_split):
                        # Store species as species+genus since species aren't unique
                        if i == 7:
                            species_aware_taxonomy = "; ".join([taxons_split[i-1],taxons_split[i]])
                        else:
                            species_aware_taxonomy = taxonomies_split.strip()

                        if species_aware_taxonomy not in taxonomy_name_to_id:
                            if taxonomies_split == 'Root':
                                level = 'root'
                                parent_id = 'NULL'
                            else:
                                prefix = taxonomies_split.split('__')[0]
                                level_id = ['d','p','c','o','f','g','s'].index(prefix)
                                level = ['domain','phylum','class','order','family','genus','species'][level_id]
                                # Will throw KeyError if something is amiss

                                parent_id = taxonomy_name_to_id[taxons_split[i-1]]

                            taxonomy_input_tf.write(("\t".join([str(next_taxonomy_id), level, str(parent_id), taxonomies_split]) + "\n").encode())

                            taxonomy_name_to_id[species_aware_taxonomy] = next_taxonomy_id
                            next_taxonomy_id += 1

                    tf.write(("\t".join([str(count+1),row[0],row[1],str(taxonomy_name_to_id[species_aware_taxonomy])])+"\n").encode())
                    count += 1
                logging.info("Wrote {} rows to temp file".format(count))
                tf.flush()



                logging.info("Writing condensed OTU table to DB.. ")
                proc = subprocess.Popen(['bash','-c','sqlite3 {}'.format(sqlite_db_path)],
                    stdin=subprocess.PIPE,
                    stdout=None,
                    stderr=subprocess.PIPE,
                    universal_newlines=True)
                
                print('.separator "\\t"\n', file=proc.stdin)
                print('.import {} condensed_profiles\n'.format(tf.name), file=proc.stdin)
                
                proc.stdin.close()
                proc.wait()
                if proc.returncode != 0:
                    raise Exception("condensed profiles import command returned non-zero exit status %i.\n"\
                        "STDERR was: %s" % (
                            proc.returncode, proc.stderr.read()))      
                logging.info("Imported {} condensed lines".format(count))



            logging.info("Writing taxonomies to DB.. ")
            taxonomy_input_tf.flush()
            proc = subprocess.Popen(['bash','-c','sqlite3 {}'.format(sqlite_db_path)],
                stdin=subprocess.PIPE,
                stdout=None,
                stderr=subprocess.PIPE,
                universal_newlines=True)
            
            print('.separator "\\t"\n', file=proc.stdin)
            print('.import {} taxonomies\n'.format(taxonomy_input_tf.name), file=proc.stdin)
            
            proc.stdin.close()
            proc.wait()
            if proc.returncode != 0:
                raise Exception("taxonomies import command returned non-zero exit status %i.\n"\
                    "STDERR was: %s" % (
                        proc.returncode, proc.stderr.read()))      
            logging.info("Imported {} taxonomies".format(next_taxonomy_id))


    # logging.info("Creating indexes ..")
    # extern.run('sqlite3 {}'.format(sqlite_db_path), stdin= \
    #     "CREATE TABLE taxonomies (id INTEGER PRIMARY KEY, taxonomy_level TEXT, parent_id INTEGER, name TEXT); \n"
    #     "CREATE TABLE condensed_profiles (id INTEGER PRIMARY KEY,"
    #     " sample_name text, coverage float, taxonomy_id INTEGER);\n")
    #     extern.run('crea')

    logging.warn("TODO: Add indexes")

    logging.info("Finished")